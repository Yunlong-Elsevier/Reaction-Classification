{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0456b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/reaction-workbench-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import pkg_resources\n",
    "import sklearn\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "#from rxnfp.tokenization import *\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import rdChemReactions\n",
    "torch.cuda.is_available()\n",
    "#import rxnfp\n",
    "#from rxnfp.models import SmilesClassificationModel\n",
    "#from rxn_yields.core import SmilesTokenizer, SmilesClassificationModel§1`\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "#torch.cuda.is_available()\n",
    "# from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "#from rxnfp.tokenization import SmilesTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74c156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from rxnfp.tokenization import SmilesTokenizer\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cfc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../ReactionClassification_2024/data/pub_train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../ReactionClassification_2024/data/pub_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf41267",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['labels'].values\n",
    "y_test = test['labels'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9615446",
   "metadata": {},
   "source": [
    "### Train Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01350d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../Janssen_project/rxn-data-from-postgresql/models/reaxys_bert/checkpoint-4356432-epoch-36 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_path = '../Janssen_project/rxn-data-from-postgresql/models/reaxys_bert/checkpoint-4356432-epoch-36'\n",
    "pretrained_model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
    "tokenizer = SmilesTokenizer(vocab_file='../Janssen_project/rxn-data-from-postgresql/models/reaxys_bert/checkpoint-4356432-epoch-36/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50a71125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Name=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a75273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = X_train \n",
    "df_Name['embedding'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62203fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.pairs = []\n",
    "        self.targets = []\n",
    "        self.create_pairs()\n",
    "\n",
    "    def create_pairs(self):\n",
    "        positive_pairs = []\n",
    "        negative_pairs = []\n",
    "        positive_targets = []\n",
    "        negative_targets = []\n",
    "\n",
    "        for _, group in tqdm(self.df.groupby('labels'), desc='Positive Pairs'):\n",
    "            indices = group.index.tolist()\n",
    "            for i in range(len(indices)):\n",
    "                pair_index = (i + 1) % len(indices)\n",
    "                positive_pairs.append((indices[i], indices[pair_index]))\n",
    "                positive_targets.append(0)  # Positive pair (similar)\n",
    "        \n",
    "        labels = self.df['labels'].unique()\n",
    "\n",
    "        for label in tqdm(labels, desc='Negative Pairs'):\n",
    "            label_indices = self.df[self.df['labels'] == label].index.tolist()\n",
    "            for index in label_indices:\n",
    "                while True:\n",
    "                    # Randomly select a different label\n",
    "                    random_label = random.choice(labels)\n",
    "                    if random_label != label:\n",
    "                        break\n",
    "                random_index = random.choice(self.df[self.df['labels'] == random_label].index.tolist())\n",
    "                negative_pairs.append((index, random_index))\n",
    "                negative_targets.append(1)  # Negative pair (dissimilar)\n",
    "        self.pairs = positive_pairs + negative_pairs\n",
    "        self.targets = positive_targets + negative_targets\n",
    "\n",
    "    def print_sample_pairs_with_distances(self, num_samples):\n",
    "        from scipy.spatial.distance import euclidean\n",
    "\n",
    "        print(\"\\nSample Pairs with Distances:\")\n",
    "        sample_indices = np.random.choice(len(self.pairs), num_samples, replace=False)\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            pair = self.pairs[idx]\n",
    "            target = self.targets[idx]\n",
    "            embedding1 = self.df.loc[pair[0], 'embedding']\n",
    "            embedding2 = self.df.loc[pair[1], 'embedding']\n",
    "            distance = euclidean(embedding1, embedding2)\n",
    "\n",
    "            pair_type = \"Positive\" if target == 0 else \"Negative\"\n",
    "            print(f\"{pair_type} Pair {i + 1}:\")\n",
    "            print(f\"Reaction 1 ID: {pair[0]}\")\n",
    "            print(f\"Reaction 2 ID: {pair[1]}\")\n",
    "            print(f\"Distance: {distance:.4f}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def calculate_average_distances(self):\n",
    "        positive_distances = []\n",
    "        negative_distances = []\n",
    "\n",
    "        for idx, (index1, index2) in enumerate(self.pairs):\n",
    "            embedding1 = self.df.loc[index1, 'embedding']\n",
    "            embedding2 = self.df.loc[index2, 'embedding']\n",
    "            distance = euclidean(embedding1, embedding2)\n",
    "\n",
    "            if self.targets[idx] == 0:\n",
    "                positive_distances.append(distance)\n",
    "            else:\n",
    "                negative_distances.append(distance)\n",
    "\n",
    "        avg_positive_distance = np.mean(positive_distances)\n",
    "        avg_negative_distance = np.mean(negative_distances)\n",
    "\n",
    "        print(f\"Average Positive Pair Distance: {avg_positive_distance:.4f}\")\n",
    "        print(f\"Average Negative Pair Distance: {avg_negative_distance:.4f}\")\n",
    "\n",
    "    def plot_distance_distributions(self, num_samples=100):\n",
    "        positive_distances = []\n",
    "        negative_distances = []\n",
    "\n",
    "        sample_indices = np.random.choice(len(self.pairs), num_samples, replace=False)\n",
    "        for idx in sample_indices:\n",
    "            pair = self.pairs[idx]\n",
    "            target = self.targets[idx]\n",
    "            embedding1 = self.df.loc[pair[0], 'embedding']\n",
    "            embedding2 = self.df.loc[pair[1], 'embedding']\n",
    "            distance = euclidean(embedding1, embedding2)\n",
    "\n",
    "            if target == 0:\n",
    "                positive_distances.append(distance)\n",
    "            else:\n",
    "                negative_distances.append(distance)\n",
    "\n",
    "        plt.hist(positive_distances, bins=30, alpha=0.5, label='Positive Pairs')\n",
    "        plt.hist(negative_distances, bins=30, alpha=0.5, label='Negative Pairs')\n",
    "        plt.xlabel('Distance')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distance Distribution of Positive and Negative Pairs')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d02793d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positive Pairs: 100%|██████████| 1000/1000 [00:00<00:00, 3752.13it/s]\n",
      "Negative Pairs: 100%|██████████| 1000/1000 [03:34<00:00,  4.66it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_fraction = 0.5  # Use 50% of the data\n",
    "sample_df = df_Name.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "dataset = PairDataset(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eef4e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positive pairs: 200302\n",
      "Total number of negative pairs: 200302\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of positive pairs: {sum(1 for t in dataset.targets if t == 1)}\")\n",
    "print(f\"Total number of negative pairs: {sum(1 for t in dataset.targets if t == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89aa350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Positive Pair Distance: 1.8285\n",
      "Average Negative Pair Distance: 2.2569\n"
     ]
    }
   ],
   "source": [
    "dataset.calculate_average_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fd2c913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.plot_distance_distributions(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e8f77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionPairDataset(Dataset):\n",
    "    def __init__(self, dataframe, pairs, targets):\n",
    "        self.df = dataframe\n",
    "        self.pairs = pairs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index1, index2 = self.pairs[idx]\n",
    "        reaction1 = self.df.loc[index1, 'canonical_rxn_with_fragment_info']\n",
    "        reaction2 = self.df.loc[index2, 'canonical_rxn_with_fragment_info']\n",
    "        label = self.targets[idx]\n",
    "        return reaction1, reaction2, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f07d1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_dataset = ReactionPairDataset(df_Name, dataset.pairs, dataset.targets)\n",
    "train_size = int(0.9 * len(reaction_dataset))\n",
    "val_size = len(reaction_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(reaction_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ad4f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "983e9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(987, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97bd9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(pretrained_model.parameters(), lr=1e-6) \n",
    "total_steps = len(train_dataloader) * 10  \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c4f03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                          label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a883e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss(margin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69d43be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader):\n",
    "    pretrained_model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for reaction1, reaction2, target in dataloader:\n",
    "            inputs1 = tokenizer(reaction1, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            inputs2 = tokenizer(reaction2, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            embedding1 = pretrained_model(**inputs1).last_hidden_state[:, 0, :]\n",
    "            embedding2 = pretrained_model(**inputs2).last_hidden_state[:, 0, :]\n",
    "            \n",
    "            loss = criterion(embedding1, embedding2, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7de6e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 11267/11267 [20:40<00:00,  9.08it/s, loss=6.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 1.5493613505909412, Validation Loss: 0.32532729238224106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 11267/11267 [20:42<00:00,  9.07it/s, loss=2.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Training Loss: 0.5243102118202309, Validation Loss: 0.22996507489833587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 11267/11267 [20:50<00:00,  9.01it/s, loss=1.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Training Loss: 0.4314229673384202, Validation Loss: 0.19844357477138028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 11267/11267 [20:55<00:00,  8.98it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Training Loss: 0.3793551168401461, Validation Loss: 0.17702412028639272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 11267/11267 [20:48<00:00,  9.02it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Training Loss: 0.34411742976572646, Validation Loss: 0.16152286386718384\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "accumulation_steps = 4 \n",
    "#early_stopping_patience = 3\n",
    "best_val_loss = float('inf')\n",
    "#patience_counter = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(num_epochs):\n",
    "    pretrained_model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", mininterval=1)  # Update every 100 seconds\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (reaction1, reaction2, target) in enumerate(progress_bar):\n",
    "        inputs1 = tokenizer(reaction1, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        inputs2 = tokenizer(reaction2, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            embedding1 = pretrained_model(**inputs1).last_hidden_state[:, 0, :]\n",
    "            embedding2 = pretrained_model(**inputs2).last_hidden_state[:, 0, :]\n",
    "            loss = criterion(embedding1, embedding2, target)\n",
    "            loss = loss / accumulation_steps  # Scale the loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(pretrained_model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        # Print loss less frequently\n",
    "        if (i + 1) % (len(train_dataloader) // 10) == 0:\n",
    "            progress_bar.set_postfix(loss=total_loss / ((i + 1) // accumulation_steps if (i + 1) // accumulation_steps > 0 else 1))\n",
    "\n",
    "    val_loss = evaluate_model(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss / len(train_dataloader)}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d43590d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/fine_tuned_model_Pub/tokenizer_config.json',\n",
       " 'data/fine_tuned_model_Pub/special_tokens_map.json',\n",
       " 'data/fine_tuned_model_Pub/vocab.txt',\n",
       " 'data/fine_tuned_model_Pub/added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.save_pretrained('data/fine_tuned_model_Pub')\n",
    "tokenizer.save_pretrained('data/fine_tuned_model_Pub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f789908",
   "metadata": {},
   "source": [
    "\n",
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e24eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../ReactionClassification_2024/data/PreBertFP_Pub/X_train_PreBertFP.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9d38c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.vstack(X_train)\n",
    "X_train = np.squeeze(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55824053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.load('data/RXNFP/X_train_RXNFP.npy')\n",
    "X_test = np.load('../ReactionClassification_2024/data/PreBertFP_Pub/X_test_PreBertFP.npy',allow_pickle=True)\n",
    "#X_val = np.load('../ReactionClassification_2024/data/PreBertFP_Pub/X_val_PreBertFP.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d43e7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = np.vstack(X_test)\n",
    "X_test = np.squeeze(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fae98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b1a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reaction-workbench-env [Python]",
   "language": "python",
   "name": "conda-env-reaction-workbench-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
