{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab6e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/reaction-workbench-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import pkg_resources\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rxnfp.tokenization import *\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import rdChemReactions\n",
    "torch.cuda.is_available()\n",
    "import rxnfp\n",
    "#from rxnfp.models import SmilesClassificationModel\n",
    "#from rxn_yields.core import SmilesTokenizer, SmilesClassificationModel\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.cuda.is_available()\n",
    "# from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from rxnfp.tokenization import SmilesTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a9ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from rxnfp.tokenization import SmilesTokenizer\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa533a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../ReactionClassification_2024/data/pub_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1f7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../ReactionClassification_2024/data/pub_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc759634",
   "metadata": {},
   "source": [
    "### Train Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c26b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return(sum_embeddings / sum_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d29d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'data/fine_tuned_model_Pub'\n",
    "#model_path = 'rxn-data-from-postgresql/models/reaxys_bert/checkpoint-4356432-epoch-36'\n",
    "\n",
    "model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
    "#tokenizer = SmilesTokenizer(vocab_file='rxn-data-from-postgresql/models/reaxys_bert/checkpoint-4235420-epoch-35/vocab.txt')\n",
    "tokenizer = SmilesTokenizer(vocab_file='data/fine_tuned_model_Pub/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24025cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "val_sentence_embeddings = []\n",
    "train_sentence_embeddings = []\n",
    "test_sentence_embeddings = []\n",
    "batch= 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e66d7",
   "metadata": {},
   "source": [
    "### Test and Val Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c96c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12519/12519 [06:06<00:00, 34.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_reactions = train['canonical_rxn_with_fragment_info'].astype(str).tolist()\n",
    "for i in tqdm(range(0, len(train_reactions), batch)):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(train_reactions[i:i+batch], padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    train_sentence_embeddings.extend([x.cpu().detach().numpy() for x in mean_pooling(model_output, encoded_input['attention_mask'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572016d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OptBertFP'] = train_sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99685238",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train['OptBertFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../ReactionClassification_2024/data/OptBertFP_Pub1/X_train_OptBertFP.npy', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d02f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val.to_csv('data/PreBertFP/val_PreBertFP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b5085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1391/1391 [00:40<00:00, 34.13it/s]\n"
     ]
    }
   ],
   "source": [
    "test_reactions = test['canonical_rxn_with_fragment_info'].astype(str).tolist()\n",
    "for i in tqdm(range(0, len(test_reactions), batch)):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(test_reactions[i:i+batch], padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    test_sentence_embeddings.extend([x.cpu().detach().numpy() for x in mean_pooling(model_output, encoded_input['attention_mask'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664ed633",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['OptBertFP'] = test_sentence_embeddings\n",
    "X_test = np.array(test['OptBertFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a63adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../ReactionClassification_2024/data/OptBertFP_Pub1/X_test_OptBertFP.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00344783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('data/PreBertFP/test_PreBertFP.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d14a67",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478f537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../ReactionClassification_2024/data/OptBertFP_Pub1/X_train_OptBertFP.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69bcf283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.vstack(X_train)\n",
    "X_train = np.squeeze(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2860d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.load('data/RXNFP/X_train_RXNFP.npy')\n",
    "X_test = np.load('../ReactionClassification_2024/data/OptBertFP_Pub1/X_test_OptBertFP.npy',allow_pickle=True)\n",
    "#X_val = np.load('../ReactionClassification_2024/data/OptBertFPFinal2/X_val_OptBertFP.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46fe2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = np.vstack(X_test)\n",
    "X_test = np.squeeze(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fabfecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['labels'].values\n",
    "y_test = test['labels'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc8836",
   "metadata": {},
   "source": [
    "### Test on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f567184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.IndexFlatL2(X_train.shape[1])\n",
    "index.add(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1e063c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "batch_size = 100\n",
    "\n",
    "num_batches = (X_test.shape[0] + batch_size - 1) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917c5636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS Search on Test Data: 100%|██████████| 446/446 [03:52<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "D_test_1nn = np.zeros((X_test.shape[0], k), dtype=np.float32)\n",
    "I_test_1nn = np.zeros((X_test.shape[0], k), dtype=np.int64)\n",
    "\n",
    "for b in tqdm(range(num_batches), desc='FAISS Search on Test Data'):\n",
    "    start = b * batch_size\n",
    "    end = min((b + 1) * batch_size, X_test.shape[0])\n",
    "    D, I = index.search(X_test[start:end], k)\n",
    "    D_test_1nn[start:end, :] = D\n",
    "    I_test_1nn[start:end, :] = I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d286b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_1nn = np.array([np.argmax(np.bincount(y_train[neighbors])) for neighbors in I_test_1nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cede22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../ReactionClassification_2024/data/OptBertFP_Pub1/y_pred_test_1nn', y_pred_test_1nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a88725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_1nn = np.load('../ReactionClassification_2024/data/OptBertFP_Pub1/y_pred_test_1nn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b61b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.798836242726517\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall Accuracy: {accuracy_score(y_test, y_pred_test_1nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98200385",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test1nn = classification_report(y_test, y_pred_test_1nn, output_dict=True)\n",
    "report_df = pd.DataFrame(report_test1nn).transpose()\n",
    "df_test1nn = report_df[:-3].reset_index().rename(columns={'index': 'labels'})\n",
    "df_test1nn['test_support'] = df_test1nn['support'].astype(int)\n",
    "df_test1nn['labels'] = df_test1nn['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96c34b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_support = train['labels'].value_counts().sort_index()\n",
    "train_support_df = train_class_support.reset_index()\n",
    "train_support_df.columns = ['labels', 'train_support']\n",
    "train_support_df['labels'] = train_support_df['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b33a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_val1nn on 'CLASS-ID'\n",
    "df_test1nn_report = pd.merge(df_test1nn, train_support_df, on='labels', how='left')\n",
    "# Sort based on the number of train_support\n",
    "df_test1nn_report = df_test1nn_report.sort_values(by='train_support', ascending=False)\n",
    "df_test1nn_report = df_test1nn_report.drop(columns=['support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5617dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate macro average for precision, recall, and f1-score\n",
    "macro_precision2 = df_test1nn['precision'].mean()\n",
    "macro_recall2 = df_test1nn['recall'].mean()\n",
    "macro_f12 = df_test1nn['f1-score'].mean()\n",
    "\n",
    "# Calculate weighted average for precision, recall, and f1-score\n",
    "weighted_precision2 = (df_test1nn['precision'] * df_test1nn['test_support']).sum() / df_test1nn['test_support'].sum()\n",
    "weighted_recall2 = (df_test1nn['recall'] * df_test1nn['test_support']).sum() / df_test1nn['test_support'].sum()\n",
    "weighted_f12 = (df_test1nn['f1-score'] * df_test1nn['test_support']).sum() / df_test1nn['test_support'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e6eafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = f\"\"\"\n",
    "Macro-averages:\n",
    "- Precision: {macro_precision2:.4f}\n",
    "- Recall: {macro_recall2:.4f}\n",
    "- F1-score: {macro_f12:.4f}\n",
    "\n",
    "Weighted-averages:\n",
    "- Precision: {weighted_precision2:.4f}\n",
    "- Recall: {weighted_recall2:.4f}\n",
    "- F1-score: {weighted_f12:.4f}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55583fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro-averages:\n",
      "- Precision: 0.8172\n",
      "- Recall: 0.7422\n",
      "- F1-score: 0.7639\n",
      "\n",
      "Weighted-averages:\n",
      "- Precision: 0.8003\n",
      "- Recall: 0.7988\n",
      "- F1-score: 0.7910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3658aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reaction-workbench-env [Python]",
   "language": "python",
   "name": "conda-env-reaction-workbench-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
